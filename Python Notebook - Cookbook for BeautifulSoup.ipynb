{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#Project Goal: Develop an Automated script to find the information about aircraft\n",
    "#Project Date: 10/30/2020\n",
    "#Project Owner: Zhong He"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import urllib.request\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#parse website url as string\n",
    "URL= 'https://flightaware.com/live/aircrafttype/'\n",
    "# use urllib module to open this url\n",
    "page = urllib.request.urlopen(URL)\n",
    "# use BeautifulSoup module to cover html page into lxml format\n",
    "# lxml is the most feature-rich and easy-to-use library in Python for processing XML and HTML \n",
    "soup = BeautifulSoup(page,\"lxml\")\n",
    "# get the body part of the script\n",
    "body=soup.body"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<tr class=\"smallrow1\"><td>733</td> <td><a href=\"/live/aircrafttype/B738\">B738</a></td> <td>Boeing 737-800</td></tr>\n",
      "<tr class=\"smallrow2\"><td>591</td> <td><a href=\"/live/aircrafttype/C172\">C172</a></td> <td>Cessna Skyhawk</td></tr>\n"
     ]
    }
   ],
   "source": [
    "# find the information I want by tag and class\n",
    "all = body.findAll('tr',{'class':['smallrow1','smallrow2']})\n",
    "# the findAll function returns values as a list\n",
    "print(all[0])\n",
    "print(all[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "65 PC12 Pilatus PC-12\n",
      "51 C208 Cessna Caravan\n",
      "48 BE20 Beechcraft Super King Air 200\n",
      "39 C56X Cessna Citation Excel/XLS\n"
     ]
    }
   ],
   "source": [
    "result = []\n",
    "\n",
    "#loop through and extract the 4 aircraft that I'm interested in\n",
    "for row in all:\n",
    "    if  row.find_all(text=['Pilatus PC-12','Cessna Caravan','Beechcraft Super King Air 200','Cessna Citation Excel/XLS']):\n",
    "        content = row.get_text()\n",
    "        print(content)\n",
    "        count = content.split(' ')[0]\n",
    "        code = content.split(' ')[1]\n",
    "        Aircraft_Type = \" \".join(content.split(' ')[2:])\n",
    "        url = 'https://flightaware.com/live/aircrafttype/'+code\n",
    "        x= {'count':count,'code':code,'Aircraft Type':Aircraft_Type,'url' :url}\n",
    "        result.append(x)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>count</th>\n",
       "      <th>code</th>\n",
       "      <th>Aircraft Type</th>\n",
       "      <th>url</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>65</td>\n",
       "      <td>PC12</td>\n",
       "      <td>Pilatus PC-12</td>\n",
       "      <td>https://flightaware.com/live/aircrafttype/PC12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>51</td>\n",
       "      <td>C208</td>\n",
       "      <td>Cessna Caravan</td>\n",
       "      <td>https://flightaware.com/live/aircrafttype/C208</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>48</td>\n",
       "      <td>BE20</td>\n",
       "      <td>Beechcraft Super King Air 200</td>\n",
       "      <td>https://flightaware.com/live/aircrafttype/BE20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>39</td>\n",
       "      <td>C56X</td>\n",
       "      <td>Cessna Citation Excel/XLS</td>\n",
       "      <td>https://flightaware.com/live/aircrafttype/C56X</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  count  code                  Aircraft Type  \\\n",
       "0    65  PC12                  Pilatus PC-12   \n",
       "1    51  C208                 Cessna Caravan   \n",
       "2    48  BE20  Beechcraft Super King Air 200   \n",
       "3    39  C56X      Cessna Citation Excel/XLS   \n",
       "\n",
       "                                              url  \n",
       "0  https://flightaware.com/live/aircrafttype/PC12  \n",
       "1  https://flightaware.com/live/aircrafttype/C208  \n",
       "2  https://flightaware.com/live/aircrafttype/BE20  \n",
       "3  https://flightaware.com/live/aircrafttype/C56X  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output = pd.DataFrame (result)\n",
    "output\n",
    "output.to_excel(\"output.xlsx\", sheet_name='Sheet1', header=True, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# if you want to scrape multiple pages, you can loop through each page by finding the law of their urls:\n",
    "\n",
    "for pages in Range(10):\n",
    "    # assume that page has a number in url\n",
    "    URL= 'https://flightaware.com/live/aircrafttype/'+ pages \n",
    "    page = urllib.request.urlopen(URL)\n",
    "    soup = BeautifulSoup(page,\"lxml\")\n",
    "    body=soup.body\n",
    "\n",
    "# also, it will come in handy to define this parser as a function and call it recursively\n",
    "def get_content(URL):\n",
    "    page = urllib.request.urlopen(URL)\n",
    "    soup = BeautifulSoup(page,\"lxml\")\n",
    "    body=soup.body\n",
    "    data_main = body.findAll('div',{'class':'newlist_list_content'})   \n",
    "    tables=data_main.find_all('table')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
